package org.apache.spark;
/**
 * A coordinator that handles all global sync requests from BarrierTaskContext. Each global sync
 * request is generated by <code>BarrierTaskContext.barrier()</code>, and identified by
 * stageId + stageAttemptId + barrierEpoch. Reply all the blocking global sync requests upon
 * all the requests for a group of <code>barrier()</code> calls are received. If the coordinator is unable to
 * collect enough global sync requests within a configured time, fail all the requests and return
 * an Exception with timeout message.
 */
  class BarrierCoordinator implements org.apache.spark.rpc.ThreadSafeRpcEndpoint, org.apache.spark.internal.Logging {
  /**
   * Provide the current state of a barrier() call. A state is created when a new stage attempt
   * sends out a barrier() call, and recycled on stage completed.
   * <p>
   * param:  barrierId Identifier of the barrier stage that make a barrier() call.
   * param:  numTasks Number of tasks of the barrier stage, all barrier() calls from the stage shall
   *                 collect <code>numTasks</code> requests to succeed.
   */
  private  class ContextBarrierState {
    // not preceding
    public   ContextBarrierState (org.apache.spark.ContextBarrierId barrierId, int numTasks)  { throw new RuntimeException(); }
    private  int barrierEpoch ()  { throw new RuntimeException(); }
    public  org.apache.spark.ContextBarrierId barrierId ()  { throw new RuntimeException(); }
    private  void cancelTimerTask ()  { throw new RuntimeException(); }
    public  void clear ()  { throw new RuntimeException(); }
    public  void handleRequest (org.apache.spark.rpc.RpcCallContext requester, org.apache.spark.RequestToSync request)  { throw new RuntimeException(); }
    private  void initTimerTask ()  { throw new RuntimeException(); }
    private  boolean maybeFinishAllRequesters (scala.collection.mutable.ArrayBuffer<org.apache.spark.rpc.RpcCallContext> requesters, int numTasks)  { throw new RuntimeException(); }
    public  int numTasks ()  { throw new RuntimeException(); }
    private  scala.collection.mutable.ArrayBuffer<org.apache.spark.rpc.RpcCallContext> requesters ()  { throw new RuntimeException(); }
    private  java.util.TimerTask timerTask ()  { throw new RuntimeException(); }
  }
  // not preceding
  public   BarrierCoordinator (long timeoutInSecs, org.apache.spark.scheduler.LiveListenerBus listenerBus, org.apache.spark.rpc.RpcEnv rpcEnv)  { throw new RuntimeException(); }
  private  void cleanupBarrierStage (org.apache.spark.ContextBarrierId barrierId)  { throw new RuntimeException(); }
  private  java.lang.Object clearStateConsumer ()  { throw new RuntimeException(); }
  private  org.apache.spark.scheduler.SparkListener listener ()  { throw new RuntimeException(); }
  public  void onStart ()  { throw new RuntimeException(); }
  public  void onStop ()  { throw new RuntimeException(); }
  public  scala.PartialFunction<java.lang.Object, scala.runtime.BoxedUnit> receiveAndReply (org.apache.spark.rpc.RpcCallContext context)  { throw new RuntimeException(); }
  public  org.apache.spark.rpc.RpcEnv rpcEnv ()  { throw new RuntimeException(); }
  private  java.util.concurrent.ConcurrentHashMap<org.apache.spark.ContextBarrierId, org.apache.spark.BarrierCoordinator.ContextBarrierState> states ()  { throw new RuntimeException(); }
  private  java.util.Timer timer ()  { throw new RuntimeException(); }
}
